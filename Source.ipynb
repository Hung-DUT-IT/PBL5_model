{"cells":[{"cell_type":"markdown","metadata":{"id":"YpFsg1kQfb1E"},"source":["# Face Recognition with FaceNet and MTCNN\n","- This project aims to test FaceNet system for face recognition. FaceNet is proposed by Florian Schroff in the 2015 paper FaceNet: A Unified Embedding for Face Recognition and Clustering\n","- Project Based Learn 5, we use MTCNN algorithm for face detection and Facenet algorithm for face recognition\n","- Our dataset has about 20 classes and the number of images per layer is about 130- 150 images for each class\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4493,"status":"ok","timestamp":1681663267507,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"jZlDXW11fb1K"},"outputs":[],"source":["import numpy as np\n","import os\n","import numpy as np \n","import cv2 as cv\n","from matplotlib import pyplot as plt\n","from keras.models import load_model\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from mtcnn import MTCNN"]},{"cell_type":"markdown","metadata":{"id":"xMeDjxYOfb1N"},"source":["## Detection and Processing\n","\n","- Detect face using MTCNN"]},{"cell_type":"markdown","metadata":{"id":"22JbDBDtfb1f"},"source":["### paths and vairables"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5411,"status":"ok","timestamp":1681663272912,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"vlVtruFyfb1h"},"outputs":[],"source":["target_size = (160, 160)\n","confidence_t = 0.99\n","detector = MTCNN()\n","encode_lable = LabelEncoder()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1681663272912,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"YR3NASAlfb1n"},"outputs":[],"source":["def normalize(img):\n","    mean, std = img.mean(), img.std()\n","    return (img - mean) / std"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1681663272913,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"OQpFRVZlfb1q"},"outputs":[],"source":["def get_face(frame, box):\n","    x, y, width, height = box\n","    x, y = abs(x), abs(y)\n","    face = frame[y: y + height, x: x + width]\n","    face = cv.resize(face, target_size)\n","    # face = normalize(face)\n","    return face, (x, y), (x + width, y + height)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1681663272913,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"RPvSVr0rfb1t"},"outputs":[],"source":["def dectect_face_of_video(path):\n","    faces_result = []\n","    video = cv.VideoCapture(path)\n","    t = 0\n","    while video.isOpened() :\n","        t += 1\n","        ret, frame = video.read()\n","        if t % 2 != 0:\n","            continue\n","        if ret:\n","            rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n","            faces = detector.detect_faces(rgb_frame)\n","            if len(faces) > 0:\n","                for face in faces:\n","                    if face['confidence'] > confidence_t:\n","                        face_image, dpt1, dpt2 = get_face( rgb_frame, face['box'])\n","                        faces_result.append(np.array(face_image))\n","            else:\n","                continue\n","        else:\n","            break\n","    video.release()\n","    cv.destroyAllWindows()\n","    return np.array(faces_result)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1681663272914,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"OQ00rCtnfb1x"},"outputs":[],"source":["def dectect_faces(BASE_DIR):\n","    Faces = []\n","    Lables = []\n","    \n","    DataSet_dir = os.path.join(BASE_DIR, \"DataSet\")\n","    Raw_img_dir = os.path.join(DataSet_dir, \"raw\")\n","\n","    for root, dirs, files in os.walk(Raw_img_dir):\n","        for file in files:\n","            if file.endswith(\"mp4\"):\n","                path = os.path.join(root, file)\n","                label = os.path.basename(root)\n","\n","                single_faces = dectect_face_of_video(path)\n","\n","                labels = [label for _ in range(len(single_faces))]\n","\n","                Faces.extend(single_faces)\n","                Lables.extend(labels)\n","\n","                directory_path = os.path.join( Raw_img_dir.replace(\"raw\", \"processed\"), label)\n","                os.makedirs(directory_path, exist_ok=True)\n","\n","                for i, face in enumerate(single_faces):\n","                    new_filename = os.path.join(directory_path, os.path.splitext(file)[0]) + \"_\" + str(i) + \".jpg\"\n","\n","                    cv.imwrite(new_filename, cv.cvtColor( face, cv.COLOR_RGB2BGR))\n","\n","    return np.array(Faces), np.array(Lables)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":29394,"status":"error","timestamp":1681665900011,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"oHDxxD-RvUIP","outputId":"6b8db681-abdb-4d6e-9162-82a71416757e"},"outputs":[],"source":["dectect_faces(\"C:/Users/huuhu/Learning/Data_Analytics/PBL5_model/\")"]},{"cell_type":"markdown","metadata":{"id":"23aFHXu4fb12"},"source":["## Load Face and Label From Precessed"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1681665900012,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"YCJnRKLnfb13"},"outputs":[],"source":["def extract_face(filename):\n","    image = Image.open(filename)\n","    pixels = np.asarray(image)\n","    return pixels"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1681665900013,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"szgel9pdfb14"},"outputs":[],"source":["def load_face(dir):\n","    faces = list()\n","    for filename in os.listdir(dir):\n","        path = dir + filename\n","        face = extract_face(path)\n","        faces.append(face)\n","    return faces"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900014,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"5O-3Ns1vfb14"},"outputs":[],"source":["def load_dataset(dir):\n","    X, y = list(), list()\n","    for subdir in os.listdir(dir):\n","        path = dir + subdir + '/'\n","        faces = load_face(path)\n","        labels = [subdir for i in range(len(faces))]\n","        print(\"load %d sample for class: %s\" % (len(faces),subdir))\n","        X.extend(faces)\n","        y.extend(labels)\n","    return np.asarray(X), np.asarray(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900014,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"BysUt2Iofb15"},"outputs":[],"source":["#load data\n","X, y = load_dataset(\"/content/gdrive/MyDrive/Document/Colab_Notebooks/PBL5_model/DataSet/processed/\")\n","#split data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, y_test.shape)\n","#save\n","np.savez_compressed(\"/content/gdrive/MyDrive/Document/Colab_Notebooks/PBL5_model/dataset_faces_20cls.npz\", X_train, y_train, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900015,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"G2N9aZ-Pfb19"},"outputs":[],"source":["#load face dataset\n","data = np.load(\"/content/gdrive/MyDrive/Document/Colab_Notebooks/PBL5_model/dataset_faces_17cls.npz\")\n","X_train, y_train, X_test, y_test = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","print('Loaded: ', X_train.shape, y_train.shape, X_test.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"99lrk9xwfb1-"},"source":["**Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900016,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"LiWUh-P6fb1_"},"outputs":[],"source":["np.random.seed(42)\n","IMG_W, IMG_H, IMG_C = (160, 160, 3)"]},{"cell_type":"markdown","metadata":{"id":"fysn98lwfb1_"},"source":["## Data Visualization "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900016,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"N9qgAMkWfb1_"},"outputs":[],"source":["def show_data(\n","    images: np.ndarray,\n","    labels: np.ndarray,\n","    GRID: tuple=(15, 6),\n","    FIGSIZE: tuple=(25, 50),\n","    recog_fn = None,\n","    database = None,\n",") -> None:\n","    plt.figure(figsize=FIGSIZE)\n","    n_rows, n_cols = GRID\n","    n_images = n_rows * n_cols\n","    \n","    for index in range(n_images):\n","        image_index = np.random.randint(len(images))\n","        image, label = images[image_index], labels[image_index]\n","        \n","        plt.subplot(n_rows, n_cols, index+1)\n","        \n","        plt.imshow(image)\n","        plt.axis('off')\n","        \n","        if recog_fn is None:\n","            plt.title(label)\n","        else:\n","            recognized = recog_fn(image, database)\n","            plt.title(f\"True:{label}\\nPred:{recognized}\")\n","    plt.tight_layout()\n","    plt.show()\n","show_data(images=X_train, labels= y_train)"]},{"cell_type":"markdown","metadata":{"id":"s0WzPRjUfb2A"},"source":["## Train model Inception Resnet V2 For extract feature"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900016,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"DqI8x1r6fb2A"},"outputs":[],"source":["def encode_lables(y):\n","    encode_lable.fit(y)\n","    y = encode_lable.transform(y)\n","    return y"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1681665900017,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"zS9d9TCnfb2B"},"outputs":[],"source":["from keras.layers import Conv2D, Activation, Input, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Concatenate, Lambda, add, GlobalAveragePooling2D\n","from keras.models import Model\n","from keras.utils import to_categorical\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","from keras.optimizers import Adam"]},{"cell_type":"markdown","metadata":{"id":"f3mBSBmNfb2B"},"source":["### Build ararchitecture Inception Resnet"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900017,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"T9JOwxuSfb2C"},"outputs":[],"source":["def scaling(x, scale):\n","    return x * scale\n","\n","\n","def conv2d_bn(x, filters, kernel_size, strides=1, padding='same', use_bias=False, name=None, activation='relu'):\n","    \"\"\"\n","    Utility function to apply Conv2D + Batch normalization + activation.\n","    \"\"\"\n","    x = Conv2D(filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias, name=name)(x)\n","    x = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001, scale=False, name=name + '_BatchNorm')(x)\n","\n","    x = Activation(activation, name=name + '_Activation')(x)\n","    return x\n","# def conv2d_branch()\n","\n","def Stem(x):\n","  x = conv2d_bn(x, 32, 3, strides=2, padding='valid', use_bias=False, name='Conv2d_1a_3x3')\n","  x = conv2d_bn(x, 32, 3, strides=1, padding='valid', use_bias=False, name='Conv2d_2a_3x3')\n","  x = conv2d_bn(x, 96, 3, strides=1, padding='same', use_bias=False, name='Conv2d_2b_3x3')\n","\n","  branch_0 = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n","  branch_1 = conv2d_bn(x, 96, 3, strides=2, padding='valid', use_bias=False, name='Conv2d_3a_3x3')\n","  x = Concatenate(axis=3, name='3a_Concatenate')([branch_0, branch_1])\n","\n","  branch_0 = conv2d_bn(x, 64, 1, strides=1, padding='same', use_bias=False, name='Conv2d_branch_0_1a_1x1')\n","  branch_0 = conv2d_bn(branch_0, 96, 3, strides=1, padding='same', use_bias=False, name='Conv2d_branch_0_2a_3x3')\n","\n","  branch_1 = conv2d_bn(x, 64, 1, strides=1, padding='same', use_bias=False, name='Conv2d_branch_1_1b_1x1')\n","  branch_1 = conv2d_bn(branch_1, 64, [7, 1], strides=1, padding='same', use_bias=False, name='Conv2d_branch_1_2b_7x1')\n","  branch_1 = conv2d_bn(branch_1, 64, [1, 7], strides=1, padding='same', use_bias=False, name='Conv2d_branch_1_3b_7x1')\n","  branch_1 = conv2d_bn(branch_1, 96, 3, strides=1, padding='valid', use_bias=False, name='Conv2d_branch_1_4b_3x3')\n","  x = Concatenate(axis=3, name='4a_Concatenate')([branch_0, branch_1])\n","\n","  branch_0 = MaxPooling2D(3, strides=2, name='MaxPool_5a_3x3')(x)\n","  branch_1 = conv2d_bn(x, 192, 3, strides=2, padding='valid', use_bias=False, name='Conv2d_5a_3x3')\n","  x = Concatenate(axis=3, name='5a_Concatenate')([branch_0, branch_1])\n","\n","  return x\n","\n","def inception_ResNet_A(x):\n","  names = ['Block35_1', 'Block35_2', 'Block35_3', 'Block35_4', 'Block35_5','Block35_6', 'Block35_7', 'Block35_8', 'Block35_9', 'Block35_10']\n","  for i in names:\n","      branch_0 = conv2d_bn(x, 32, 1, strides=1, padding='same', use_bias=False, name=i + '_Branch_0_Conv2d_1x1')\n","\n","      branch_1 = conv2d_bn(x, 32, 1, strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0a_1x1')\n","      branch_1 = conv2d_bn(branch_1, 32, 3, strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0b_3x3')\n","\n","      branch_2 = conv2d_bn(x, 32, 1, strides=1, padding='same', use_bias=False, name=i + '_Branch_2_Conv2d_0a_1x1')\n","      branch_2 = conv2d_bn(branch_2, 48, 3, strides=1, padding='same', use_bias=False, name=i + '_Branch_2_Conv2d_0b_3x3')\n","      branch_2 = conv2d_bn(branch_2, 64, 3, strides=1, padding='same', use_bias=False, name=i + '_Branch_2_Conv2d_0c_3x3')\n","\n","      branches = [branch_0, branch_1, branch_2]\n","      mixed = Concatenate(axis=3, name=i + '_Concatenate')(branches)\n","      up = Conv2D(384, 1, strides=1, padding='same', use_bias=True, name=i + '_Conv2d_1x1')(mixed)\n","      up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.17})(up)\n","      x = add([x, up])\n","      x = Activation('relu', name=i + '_Activation')(x)\n","  return x\n","\n","def reduction_A(x):\n","  # Mixed 6a (Reduction-A block):\n","  branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid', use_bias=False, name='Mixed_6a_Branch_0_Conv2d_1a_3x3')\n","\n","  branch_1 = conv2d_bn(x, 192, 1, strides=1, padding='same', use_bias=False, name='Mixed_6a_Branch_1_Conv2d_0a_1x1')\n","  branch_1 = conv2d_bn(branch_1, 224, 3, strides=1, padding='same', use_bias=False, name='Mixed_6a_Branch_1_Conv2d_0b_3x3')\n","  branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid', use_bias=False, name='Mixed_6a_Branch_1_Conv2d_1a_3x3')\n","\n","  branch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_6a_Branch_2_MaxPool_1a_3x3')(x)\n","\n","  branches = [branch_0, branch_1, branch_pool]\n","  x = Concatenate(axis=3, name='Mixed_6a')(branches)\n","  return x\n","\n","def inception_resNet_B(x):\n","  # 10x Block17 (Inception-ResNet-B block):\n","  names = ['Block17_1', 'Block17_2', 'Block17_3', 'Block17_4', 'Block17_5',\n","           'Block17_6', 'Block17_7', 'Block17_8', 'Block17_9', 'Block17_10',\n","           'Block17_11', 'Block17_12', 'Block17_13', 'Block17_14', 'Block17_15',\n","           'Block17_16', 'Block17_17', 'Block17_18', 'Block17_19', 'Block17_20']\n","\n","  for i in names:\n","      branch_0 = conv2d_bn(x, 192, 1, strides=1, padding='same', use_bias=False, name=i + '_Branch_0_Conv2d_1x1')\n","\n","      branch_1 = conv2d_bn(x, 128, 1, strides=1, padding='same',use_bias=False, name=i + '_Branch_1_Conv2d_0a_1x1')\n","      branch_1 = conv2d_bn(branch_1, 160, [1, 7], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0b_1x7')\n","      branch_1 = conv2d_bn(branch_1, 192, [7, 1], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0c_7x1')\n","\n","      branches = [branch_0, branch_1]\n","      mixed = Concatenate(axis=3, name=i + '_Concatenate')(branches)\n","      up = Conv2D(1152, 1, strides=1, padding='same', use_bias=True, name=i + '_Conv2d_1x1')(mixed)\n","      up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.1})(up)\n","      x = add([x, up])\n","      x = Activation('relu', name=i + '_Activation')(x)\n","\n","  return x\n","\n","def reduction_B(x):\n","  # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n","  branch_0 = conv2d_bn(x, 256, 1, strides=1, padding='same', use_bias=False, name='Mixed_7a_Branch_0_Conv2d_0a_1x1')\n","  branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid', use_bias=False, name='Mixed_7a_Branch_0_Conv2d_1a_3x3')\n","\n","  branch_1 = conv2d_bn(x, 256, 1, strides=1, padding='same', use_bias=False, name='Mixed_7a_Branch_1_Conv2d_0a_1x1')\n","  branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid', use_bias=False, name='Mixed_7a_Branch_1_Conv2d_1a_3x3')\n","\n","  branch_2 = conv2d_bn(x, 256, 1, strides=1, padding='same', use_bias=False, name='Mixed_7a_Branch_2_Conv2d_0a_1x1')\n","  branch_2 = conv2d_bn(branch_2, 288, 3, strides=1, padding='same', use_bias=False, name='Mixed_7a_Branch_2_Conv2d_0b_3x3')\n","  branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid', use_bias=False, name='Mixed_7a_Branch_2_Conv2d_1a_3x3')\n","\n","  branch_pool = MaxPooling2D(3, strides=2, padding='valid', name='Mixed_7a_Branch_3_MaxPool_1a_3x3')(x)\n","  \n","  branches = [branch_0, branch_1, branch_2, branch_pool]\n","  x = Concatenate(axis=3, name='Mixed_7a')(branches)\n","  return x\n","\n","def inception_resNet_C(x):\n","  # 5x Block8 (Inception-ResNet-C block):\n","\n","  names = ['Block8_1', 'Block8_2', 'Block8_3', 'Block8_4', 'Block8_5',\n","           'Block8_6', 'Block8_7', 'Block8_8', 'Block8_9', 'Block8_10']\n","  for i in names:\n","      branch_0 = conv2d_bn(x, 192, 1, strides=1, padding='same', use_bias=False, name=i + '_Branch_0_Conv2d_1x1')\n","\n","      branch_1 = conv2d_bn(x, 192, 1, strides=1, padding='same',use_bias=False, name=i + '_Branch_1_Conv2d_0a_1x1')\n","      branch_1 = conv2d_bn(branch_1, 224, [1, 3], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0b_1x3')\n","      branch_1 = conv2d_bn(branch_1, 256, [3, 1], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0b_3x1')\n","      branches = [branch_0, branch_1]\n","      mixed = Concatenate(axis=3, name=i + '_Concatenate')(branches)\n","      up = Conv2D(2144, 1, strides=1, padding='same', use_bias=True, name=i + '_Conv2d_1x1')(mixed)\n","      up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={'scale': 0.2})(up)\n","      x = add([x, up])\n","      x = Activation('relu', name=i + '_Activation')(x)\n","\n","  return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900017,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"e2KoxdgIfb2D"},"outputs":[],"source":["def create_inception_resnet_v2(input):\n","    x = Stem(input)\n","    x = inception_ResNet_A(x)\n","    x = reduction_A(x)\n","    x = inception_resNet_B(x)\n","    x = reduction_B(x)\n","    x = inception_resNet_C(x)\n","    # Classification block  \n","    \n","    x = GlobalAveragePooling2D(name='AvgPool')(x)\n","    x = Dropout(1.0 - 0.8, name='Dropout')(x)\n","    # Bottleneck\n","    x = Flatten()(x)\n","    x = Dense(128, activation='softmax', use_bias=False, name='Bottleneck')(x)\n","    x = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False, name='Bottleneck_BatchNorm')(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1681665900018,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"NRmXQm3mfb2E"},"outputs":[],"source":["def trainning_weigth(X_data, y_data):\n","\n","    ip = Input(shape=(160, 160, 3))\n","\n","    inception_resnet_v2 = create_inception_resnet_v2(ip)\n","    # Create model\n","    model = Model(inputs=ip, outputs=inception_resnet_v2, name='inception_resnet_v1')\n","    model.compile(optimizer=Adam(learning_rate=0.00001, beta_1=0.9, beta_2=0.999), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    # Split the training set into training and validation sets\n","    X_train, X_val, y_train, y_val = train_test_split( X_data, y_data, test_size=0.2,  shuffle=True, random_state=5)\n","    y_train = to_categorical(y_train, 128)\n","    y_val = to_categorical(y_val, 128)\n","    # Define early stopping and model checkpoint callbacks\n","    early_stopping = EarlyStopping( monitor='val_loss', patience=10, verbose=1, mode='min')\n","    model_checkpoint = ModelCheckpoint('/content/gdrive/MyDrive/Document/Colab_Notebooks/PBL5_model/Model/best_weights.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n","    # Train the model\n","    model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1, validation_data=(X_val, y_val), callbacks=[early_stopping, model_checkpoint])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"sotnyV6Pfb2H"},"source":["### Trainning Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1681665900018,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"WkofZqHWfb2I"},"outputs":[],"source":["y_train = encode_lables(y_train)\n","\n","model = trainning_weigth(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"HOqU3yDSfb2I"},"source":["## Extract Feature -> tensor 128 dim "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"aborted","timestamp":1681665900018,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"1MGBQzD8fb2J"},"outputs":[],"source":["def get_encode( model, face):\n","    return model.predict(np.expand_dims(face, axis=0))[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1681665900019,"user":{"displayName":"Lê Hũu Hưng","userId":"14196924869702780337"},"user_tz":-420},"id":"MFOxewi3fb2J"},"outputs":[],"source":["def get_encodes( model, faces):\n","    Features = []\n","    for face in faces:\n","        Features.append(get_encode(model, face))\n","    return np.asarray(Features)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
