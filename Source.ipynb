{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(filename):\n",
    "    image = Image.open(filename)\n",
    "    pixels = np.asarray(image)\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_face(dir):\n",
    "    faces = list()\n",
    "    for filename in os.listdir(dir):\n",
    "        path = dir + filename\n",
    "        face = extract_face(path)\n",
    "        faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir):\n",
    "    X, y = list(), list()\n",
    "    for subdir in os.listdir(dir):\n",
    "        path = dir + subdir + '/'\n",
    "        faces = load_face(path)\n",
    "        labels = [subdir for i in range(len(faces))]\n",
    "        print(\"load %d sample for class: %s\" % (len(faces),subdir))\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "X, y = load_dataset('../PBL5_model/DataSet/processed/')\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "#save\n",
    "np.savez_compressed('dataset_faces_17cls.npz', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load face dataset\n",
    "data = np.load('dataset_faces_17cls.npz')\n",
    "X_train, y_train, X_test, y_test = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "IMG_W, IMG_H, IMG_C = (160, 160, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(\n",
    "    images: np.ndarray,\n",
    "    labels: np.ndarray,\n",
    "    GRID: tuple=(15, 6),\n",
    "    FIGSIZE: tuple=(25, 50),\n",
    "    recog_fn = None,\n",
    "    database = None,\n",
    ") -> None:\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    n_rows, n_cols = GRID\n",
    "    n_images = n_rows * n_cols\n",
    "    \n",
    "    for index in range(n_images):\n",
    "        image_index = np.random.randint(len(images))\n",
    "        image, label = images[image_index], labels[image_index]\n",
    "        \n",
    "        plt.subplot(n_rows, n_cols, index+1)\n",
    "        \n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if recog_fn is None:\n",
    "            plt.title(label)\n",
    "        else:\n",
    "            recognized = recog_fn(image, database)\n",
    "            plt.title(f\"True:{label}\\nPred:{recognized}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "show_data(images=X_train, labels= y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_lable = LabelEncoder()\n",
    "\n",
    "def encode_lables(y):\n",
    "    encode_lable.fit(y)\n",
    "    y = encode_lable.transform(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Activation, Input, MaxPooling2D, Dense, Dropout, BatchNormalization, Concatenate, Lambda, add, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(x, scale):\n",
    "    return x * scale\n",
    "\n",
    "\n",
    "def conv2d_bn(x, filters, kernel_size, strides=1, padding='same', use_bias=False, name=None, activation='relu'):\n",
    "    \"\"\"\n",
    "    Utility function to apply Conv2D + Batch normalization + activation.\n",
    "    \"\"\"\n",
    "    x = Conv2D(filters, kernel_size, strides=strides,\n",
    "               padding=padding, use_bias=use_bias, name=name)(x)\n",
    "    x = BatchNormalization(axis=3, momentum=0.995, epsilon=0.001,\n",
    "                           scale=False, name=name + '_BatchNorm')(x)\n",
    "\n",
    "    x = Activation(activation, name=name + '_Activation')(x)\n",
    "    return x\n",
    "# def conv2d_branch()\n",
    "\n",
    "\n",
    "def Stem(x):\n",
    "    x = conv2d_bn(x, 32, 3, strides=2, padding='valid',\n",
    "                  use_bias=False, name='Conv2d_1a_3x3')\n",
    "    x = conv2d_bn(x, 32, 3, strides=1, padding='valid',\n",
    "                  use_bias=False, name='Conv2d_2a_3x3')\n",
    "    x = conv2d_bn(x, 64, 3, strides=1, padding='same',\n",
    "                  use_bias=False, name='Conv2d_2b_3x3')\n",
    "    x = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n",
    "    x = conv2d_bn(x, 80, 1, strides=1, padding='valid',\n",
    "                  use_bias=False, name='Conv2d_3b_1x1')\n",
    "    x = conv2d_bn(x, 192, 3, strides=1, padding='valid',\n",
    "                  use_bias=False, name='Conv2d_4a_3x3')\n",
    "    x = conv2d_bn(x, 256, 3, strides=2, padding='valid',\n",
    "                  use_bias=False, name='Conv2d_4b_3x3')\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_ResNet_A(x):\n",
    "\n",
    "    names = ['Block35_1', 'Block35_2', 'Block35_3', 'Block35_4', 'Block35_5']\n",
    "    for i in names:\n",
    "        branch_0 = conv2d_bn(x, 32, 1, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_0_Conv2d_1x1')\n",
    "\n",
    "        branch_1 = conv2d_bn(x, 32, 1, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_1_Conv2d_0a_1x1')\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_1_Conv2d_0b_3x3')\n",
    "\n",
    "        branch_2 = conv2d_bn(x, 32, 1, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_2_Conv2d_0a_1x1')\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_2_Conv2d_0b_3x3')\n",
    "        branch_2 = conv2d_bn(branch_2, 32, 3, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_2_Conv2d_0c_3x3')\n",
    "\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "        mixed = Concatenate(axis=3, name=i + '_Concatenate')(branches)\n",
    "        up = Conv2D(256, 1, strides=1, padding='same',\n",
    "                    use_bias=True, name=i + '_Conv2d_1x1')(mixed)\n",
    "        up = Lambda(scaling, output_shape=K.int_shape(up)\n",
    "                    [1:], arguments={'scale': 0.17})(up)\n",
    "        x = add([x, up])\n",
    "        x = Activation('relu', name=i + '_Activation')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def reduction_A(x):\n",
    "    # Mixed 6a (Reduction-A block):\n",
    "    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid',\n",
    "                         use_bias=False, name='Mixed_6a_Branch_0_Conv2d_1a_3x3')\n",
    "\n",
    "    branch_1 = conv2d_bn(x, 192, 1, strides=1, padding='same',\n",
    "                         use_bias=False, name='Mixed_6a_Branch_1_Conv2d_0a_1x1')\n",
    "    branch_1 = conv2d_bn(branch_1, 192, 3, strides=1, padding='same',\n",
    "                         use_bias=False, name='Mixed_6a_Branch_1_Conv2d_0b_3x3')\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid',\n",
    "                         use_bias=False, name='Mixed_6a_Branch_1_Conv2d_1a_3x3')\n",
    "\n",
    "    branch_pool = MaxPooling2D(\n",
    "        3, strides=2, padding='valid', name='Mixed_6a_Branch_2_MaxPool_1a_3x3')(x)\n",
    "\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = Concatenate(axis=3, name='Mixed_6a')(branches)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_resNet_B(x):\n",
    "    # 10x Block17 (Inception-ResNet-B block):\n",
    "    names = ['Block17_1', 'Block17_2', 'Block17_3', 'Block17_4', 'Block17_5',\n",
    "             'Block17_6', 'Block17_7', 'Block17_8', 'Block17_9', 'Block17_10']\n",
    "\n",
    "    for i in names:\n",
    "        branch_0 = conv2d_bn(x, 128, 1, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_0_Conv2d_1x1')\n",
    "\n",
    "        branch_1 = conv2d_bn(x, 128, 1, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_1_Conv2d_0a_1x1')\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [\n",
    "                             1, 7], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0b_1x7')\n",
    "        branch_1 = conv2d_bn(branch_1, 128, [\n",
    "                             7, 1], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0c_7x1')\n",
    "\n",
    "        branches = [branch_0, branch_1]\n",
    "        mixed = Concatenate(axis=3, name=i + '_Concatenate')(branches)\n",
    "        up = Conv2D(896, 1, strides=1, padding='same',\n",
    "                    use_bias=True, name=i + '_Conv2d_1x1')(mixed)\n",
    "        up = Lambda(scaling, output_shape=K.int_shape(up)\n",
    "                    [1:], arguments={'scale': 0.1})(up)\n",
    "        x = add([x, up])\n",
    "        x = Activation('relu', name=i + '_Activation')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def reduction_B(x):\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    branch_0 = conv2d_bn(x, 256, 1, strides=1, padding='same',\n",
    "                         use_bias=False, name='Mixed_7a_Branch_0_Conv2d_0a_1x1')\n",
    "    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid',\n",
    "                         use_bias=False, name='Mixed_7a_Branch_0_Conv2d_1a_3x3')\n",
    "\n",
    "    branch_1 = conv2d_bn(x, 256, 1, strides=1, padding='same',\n",
    "                         use_bias=False, name='Mixed_7a_Branch_1_Conv2d_0a_1x1')\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3, strides=2, padding='valid',\n",
    "                         use_bias=False, name='Mixed_7a_Branch_1_Conv2d_1a_3x3')\n",
    "\n",
    "    branch_2 = conv2d_bn(x, 256, 1, strides=1, padding='same',\n",
    "                         use_bias=False, name='Mixed_7a_Branch_2_Conv2d_0a_1x1')\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 3, strides=1, padding='same',\n",
    "                         use_bias=False, name='Mixed_7a_Branch_2_Conv2d_0b_3x3')\n",
    "    branch_2 = conv2d_bn(branch_2, 256, 3, strides=2, padding='valid',\n",
    "                         use_bias=False, name='Mixed_7a_Branch_2_Conv2d_1a_3x3')\n",
    "\n",
    "    branch_pool = MaxPooling2D(\n",
    "        3, strides=2, padding='valid', name='Mixed_7a_Branch_3_MaxPool_1a_3x3')(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = Concatenate(axis=3, name='Mixed_7a')(branches)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_resNet_C(x):\n",
    "    # 5x Block8 (Inception-ResNet-C block):\n",
    "\n",
    "    names = ['Block8_1', 'Block8_2', 'Block8_3',\n",
    "             'Block8_4', 'Block8_5', 'Block8_6']\n",
    "    for i in names:\n",
    "        branch_0 = conv2d_bn(x, 192, 1, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_0_Conv2d_1x1')\n",
    "\n",
    "        branch_1 = conv2d_bn(x, 192, 1, strides=1, padding='same',\n",
    "                             use_bias=False, name=i + '_Branch_1_Conv2d_0a_1x1')\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [\n",
    "                             1, 3], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0b_1x3')\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [\n",
    "                             3, 1], strides=1, padding='same', use_bias=False, name=i + '_Branch_1_Conv2d_0b_3x1')\n",
    "        branches = [branch_0, branch_1]\n",
    "        mixed = Concatenate(axis=3, name=i + '_Concatenate')(branches)\n",
    "        up = Conv2D(1792, 1, strides=1, padding='same',\n",
    "                    use_bias=True, name=i + '_Conv2d_1x1')(mixed)\n",
    "        up = Lambda(scaling, output_shape=K.int_shape(up)\n",
    "                    [1:], arguments={'scale': 0.2})(up)\n",
    "        x = add([x, up])\n",
    "        x = Activation('relu', name=i + '_Activation')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inception_resnet_v2(input):\n",
    "    x = Stem(input)\n",
    "    x = inception_ResNet_A(x)\n",
    "    x = reduction_A(x)\n",
    "    x = inception_resNet_B(x)\n",
    "    x = reduction_B(x)\n",
    "    x = inception_resNet_C(x)\n",
    "    # Classification block\n",
    "    x = GlobalAveragePooling2D(name='AvgPool')(x)\n",
    "    x = Dropout(1.0 - 0.8, name='Dropout')(x)\n",
    "    # Bottleneck\n",
    "    x = Dense(128, activation='relu', use_bias=False, name='Bottleneck')(x)\n",
    "    x = BatchNormalization(momentum=0.995, epsilon=0.001,\n",
    "                           scale=False, name='Bottleneck_BatchNorm')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainning_weigth(X_data, y_data):\n",
    "\n",
    "    ip = Input(shape=(160, 160, 3))\n",
    "\n",
    "    inception_resnet_v2 = create_inception_resnet_v2(ip)\n",
    "    # Create model\n",
    "    model = Model(inputs=ip, outputs=inception_resnet_v2,\n",
    "                  name='inception_resnet_v1')\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Split the training set into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_data, y_data, test_size=0.2,  shuffle=True, random_state=5)\n",
    "    y_train = to_categorical(y_train, 128)\n",
    "    y_val = to_categorical(y_val, 128)\n",
    "    # Define early stopping and model checkpoint callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint('PBL5_model/best_weights.h5', save_best_only=True,\n",
    "                                       save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val),\n",
    "               callbacks=[early_stopping, model_checkpoint])\n",
    "    return model\n",
    "## Train Model\n",
    "y_train = encode_lables(y_train)\n",
    "\n",
    "model = trainning_weigth(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
